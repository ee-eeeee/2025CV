# 深度学习与计算机视觉小组汇报总结

## 幻灯片 1：封面

### 标题

深度学习与计算机视觉小组汇报总结

### 副标题

—— 技术探索与实践应用

### 汇报人

\[小组名称]

### 日期

\[具体日期]

## 幻灯片 2：目录

PyTorch 与开发环境管理汇报总结

研究现状、数据集和指标

模型的训练和检测分析

模型分析的指标对比

总结与致谢

## 幻灯片 3：PyTorch 环境搭建

### GPU 驱动安装​

在命令行中输入：nvidia-smi.exe，查看显卡支持的最新的 cuda 版本，参考版本安装 CUDA 和 CuDNN。
​
### vscode 安装​

官网下载，建议安装插件：chinese，python，pylance。​

### conda 安装​

官网下载，注意配置环境变量，并将终端导入 vscode。
​
### 创建虚拟环境​

使用 conda 工具创建虚拟环境，建议 Python 版本不小于 3.9。

## 幻灯片4： 通过 Anaconda 和 pip 安装 PyTorch 的不同方法​

### Anaconda 安装流程​

创建新环境，指定 Python 版本，使用conda install命令添加 PyTorch，确保 GPU 支持（可选）。​

### pip 安装步骤​

确保已安装 Python 和 pip，运行pip install torch torchvision torchaudio，按需添加 CUDA 版本参数。​

### 安装对比考量​

Anaconda 提供统一管理，适合复杂依赖；pip 更灵活，适用于已有环境的扩展。

## 幻灯片5：验证安装是否成功及常见问题解决方案

### 检查版本信息

使用`torch.__version__`命令查询当前安装的 PyTorch 版本，确保满足项目需求。

### 导入 torch 库

在 Python 环境中尝试导入 torch 库，确认没有出现任何错误信息。

### 检查 CUDA 可用

输入`print(torch.cuda.is_available())`查看当前 GPU 是否可用。

### 解决依赖冲突

当出现依赖库冲突时，可问 deepseek 寻求帮助。

### 运行 Python 程序

启动 Python 环境，确保能够正常运行。

## 幻灯片6 Conda 和 pip 的区别与联系

### Conda vs pip

Conda是Anaconda的一部分，能管理包及其依赖，支持多语言。pip专为Python设计，处理Python包更高效。

### 环境管理

Conda擅长创建和管理虚拟环境，确保不同项目间依赖隔离。pip则需额外工具如virtualenv来实现。

### 依赖解决

Conda能自动解决依赖冲突，适合复杂项目。pip可能需要手动解决依赖问题，适用于简单项目。

### 生态系统

Conda覆盖科学计算领域广泛，包含非Python包。pip聚焦Python生态，资源丰富，更新快。


## 幻灯片7 如何使用requirements.txt进行依赖管理

### 文件的作用

记录项目所需的所有 Python 包及其版本，确保环境一致性。

### 创建方法

使用pip freeze > requirements.txt命令，自动导出当前环境中的所有包。

### 更新策略

手动编辑添加新包或更新版本，保持文件与项目需求同步。

### 部署应用

分享或部署时，执行pip install -r requirements.txt，快速重建相同环境。

## 幻灯片8 高级功能：构建自定义包并发布

### 自定义包结构

设计清晰的目录结构，包含__init__.py，使模块可导入。

### 编写 setup.py

定义包元数据，如名称、版本和依赖项，便于自动化构建。

### 测试包安装

在虚拟环境中测试安装，确保无错误，功能正常。

### 发布至 PyPI

使用twine上传至 Python Package Index，供他人下载使用。

## 幻灯片9 为什么需要使用虚拟环境：隔离项目依赖

### 确保环境一致性

提供独立的依赖库版本，避免项目间依赖冲突，确保项目稳定运行。

### 简化部署流程

精确复制项目所需环境，保证本地开发与生产环境一致，提高代码移植性和可维护性。

### 提升团队协作

便于打包和分享项目依赖，使新成员快速加入项目，提高协作效率。

## 幻灯片10 创建、激活和删除虚拟环境

### 创建虚拟环境

使用 Python 内置的venv模块或 Conda 轻松创建，隔离项目依赖，确保独立运行。

### 激活虚拟环境

Windows：venv\Scripts\activate
Linux/Mac：source venv/bin/activate

### 删除虚拟环境

直接删除虚拟环境目录，彻底清除依赖，释放系统资源。

## 幻灯片11 在虚拟环境中安装和管理包

### 安装所需软件包

使用pip install或conda install命令安装，满足项目需求。

### 查看已安装包列表

确认所有依赖项正确安装，便于排查问题。

### 定期更新包

获取最新功能和修复，保持项目先进性和安全性。

### 移除不再需要的包

使用pip uninstall或conda remove，减少资源占用。

### 确保虚拟环境

在正确的虚拟环境中操作，避免全局包冲突，保证项目独立性。

### 导出至 requirements.txt

便于环境复现和团队协作。

## 幻灯片12 代码托管平台的使用：以 GitHub 为例

### 创建账户

用邮箱注册并登录代码托管平台。

### 创建新项目

在平台上创建一个新的代码仓库。

### clone 到本地

使用 Git 命令将远程仓库克隆到本地计算机。

### 修改代码内容

在本地编辑器中对代码进行修改和优化。

### push 回远端仓库

将本地的代码更改推送到远程仓库。

### 添加分支

创建新的分支以管理不同的开发功能或版本。

### 权限管理

设置仓库的访问权限，确保团队成员能够协作开发。

## 幻灯片13 Git 基础命令学习：初始化仓库、提交更改、分支管理

### clone 项目

命令：git clone <repository-url>
作用：将远程仓库克隆到本地，以便本地开发和修改。

### 提交更改

步骤：git add <文件> → git commit -m "提交说明" → git push
作用：保存更改到本地仓库并同步至远程仓库。

### 分支管理

创建分支：git branch <分支名>
切换分支：git checkout <分支名>
作用：管理不同开发功能或版本，确保主分支稳定。

## 幻灯片 14：研究现状 —— 概念介绍

### 显著目标检测（SOD）定义

旨在识别图像中吸引人类注意力的最重要区域，模拟人类对场景醒目区域的注意力。

### 核心价值

识别图像中的突出区域可促进后续高级视觉任务，提高效率、资源管理及任务性能。

## 幻灯片 15：研究现状 —— 传统方法

### 基于局部对比度的 SOD

早期研究通过像素级中心定位估计元素独特性
利用颜色、方向、对比度等低级特征判断像素显著性

### 基于扩散的 SOD

基于图结构模型，通过扩散矩阵在图像区域传播显著性值

### 基于贝叶斯方法的 SOD

Xie 等人（2012）提出基于兴趣点凸包的方法
计算像素特定显著性先验，利用聚类技术生成边界簇

### 其他传统方法

基于目标先验的 SOD 和 经典机器学习（ML）算法

## 幻灯片 16：研究现状 —— 深度学习方法分类

### 全监督模型

依赖像素级显著目标掩码人工标注数据

### 弱监督模型

使用稀疏注释（边框、涂鸦、图像级标签）替代像素级标注

### 自监督模型

无需人工标注，通过设计自监督任务生成伪标签训练模型

## 幻灯片 17：研究现状 —— 全监督模型代表工作

### Zhao 等人（2015）

- 利用多上下文深度特征进行 SOD
- 双 CNN 分别建模超像素全局 / 局部上下文
- 融合多上下文特征回归生成显著性分数

### He 等人（2017）
- 引入子化（subitizing）辅助任务提升性能
- 基于 U-Net 架构，通过自适应权重层联合微调子化子网与 SOD 子网

### Islam 等人（2018）
- 跳跃连接策略促进编码器特征细化
- 子化任务真实掩码与像素级注释联合监督
- 多尺度特征融合生成最终显著性图

## 幻灯片 18：研究现状 —— 弱监督模型代表工作

### Wang 等人（2017a）

- 图像级标签弱监督 SOD 模型
- 联合训练分类网络与前景特征推理网络（FIN）
- 迭代条件随机场（CRF）自训练细化预测

### Sym 等人（Zhu 等人，2018）

- 基于 GAN 的 SOD 模型
- 判别器引入相关层，增强显著目标边界捕捉能力
- 幻灯片 8：研究现状 —— 自监督模型代表工作

### Jidong 等人（2025）

- 引入自我监督对比学习
- 结合 T2T-ViT 与 ViG 主干，设计图像级 / 像素级对比学习
- 可作为插件提升模型性能，优于 SOTA 方法

### Lina 等人（2025）
- 自监督预训练模型用于 RGB-D SOD
- 多模态表示学习（外观、深度增强、对比多模态）
- 跨模态融合与分层交互聚合模块
- 微调模型在 8 个数据集达最高自监督性能，减少 53% 注释工作量

## 幻灯片 19：研究现状 —— 问题与挑战

### 特征提取与聚合挑战

尽管预训练 CNN 网络具有多尺度、多层特征，许多深度学习模型在提取有吸引力的特征并进行聚合时仍面临挑战。

### 数据集偏差问题

拥有偏差较小的大规模数据集对开发 SOD 模型至关重要，训练数据集中的偏差会影响模型对复杂场景中显著目标的泛化能力。

### 复杂场景检测瓶颈

SOD 领域在一些复杂场景中仍然存在挑战。例如，当物体与外观相似的环境混合或处于杂乱的背景中时，检测性能会明显下降。

### 移动端应用需求

轻量化模型设计适配移动和嵌入式设备

## 幻灯片 20：数据集与指标 —— 公开数据集

### COD10k

- 伪装 / 隐藏物体检测数据集
- 包含 10000 张图像，源自 MSRA 数据集的像素级标记
### MSRA
- 经典显著性检测数据集
- 人工标注的像素级显著目标掩码
### DUTS
- 大规模数据集
- 10553 张训练图像，5019 张测试图像
- 50 名受试者手动标注的高精度像素级真值

## 幻灯片 21：DSS-PYTORCH—— 项目背景

### 模型特征
通过在深度监督网络中引入短连接，提升显著目标检测性能，实现深层与浅层特征交互。

### 技术优势
克服传统 FCN 模型在尺度空间的局限
增强网络捕捉显著目标全局语义和细节信息的能力

## 幻灯片 22：DSS-PYTORCH——VGGNet 架构

空白页，后期添加

## 幻灯片 23：DSS-PYTORCH—— 项目原理（网络架构）

空白页，后期添加

## 幻灯片 24：DSS-PYTORCH—— 预测结果（MSRA-B 数据集）

空白页，后期添加

## 幻灯片 25：DSS-PYTORCH—— 训练结果

空白页，后期添加

## 幻灯片 26：SSLSOD 模型 —— 算法来源

空白页，后期添加

## 幻灯片 27：SSLSOD 模型 —— 算法结构

空白页，后期添加

### 第一阶段：跨模态自编码器训练

- 目标：实现 RGB 与深度图的双向多尺度重建
  
- 方法：
  
    输入 RGB / 深度图，通过编码器提取多尺度特征（1/2, 1/4, 1/8, 1/16）

    解码器基于特征重建原始模态图像

    损失函数：SSIM（结构相似性）+ MAE（平均绝对误差）
- 输出：跨模态特征映射关系
  
### 第二阶段：轮廓估计模型训练

- 目标：利用跨模态特征预测物体轮廓
- 方法：
    加载第一阶段预训练权重
    多尺度监督训练（输入特征尺寸：1/2 到 1/16）
    损失函数：交叉熵损失
- 输出：精确物体轮廓图

### 第三阶段：RGBD 显著目标检测模型训练
- 目标：端到端训练显著目标检测模型
- 方法：
    融合 RGB 与深度图特征，多尺度输入（1/2 到 1/16）
    损失函数：BCE（二元交叉熵）+ IOU（交并比损失）
- 数据集：DUT-RGBD、NJU2K 等 10 个基准数据集
- 评估指标：MAE、F-measure、S-measure 等 9 种

## 幻灯片 28：Scribble Annotations—— 算法来源

空白页，后期添加

## 幻灯片 29：Scribble Annotations—— 算法架构

空白页，后期添加

## 幻灯片 30：Scribble Annotations—— 关键策略

空白页，后期添加













